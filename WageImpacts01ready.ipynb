{"metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "version": "3.7.0", "file_extension": ".py"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Demography 88<br>\n", "Fall 2019<br>\n", "Carl Mason (cmason@berkeley.edu)<br>\n", "\n", "# The impact of immigration on wages \n", "\n", "## Outline\n", "1. Discuss IPUMS.org as source for final project data\n", "1. Review TVD results from Great Migration (chicago) Lab\n", "1. Discuss The Clemens paper\n", "1. Consider what a productivity measuring statistic might look like\n", "    1. Design a productivity based statistic of interest\n", "    1. Compute the statistic\n", "    1. Characterize its uncertainty with a bootstrap simulation\n", "\n", "\n", "## The Clemens paper\n", "\n", "1. Huge gains from removing restrictions on immigration\n", "   1. Reasons why the trillion dollar bill is left on the sidewalk:\n", "1. Assumptions and requirements\n", "   1. migrants from poor to rich countries see large productivity gains\n", "       1. productivity = output/unit of input in this case labor. marginal productivity = wage\n", "       1. productivity is a matter of place ?  or person (migration selectivity)?\n", "   1. gain/loss to others hard to estimate BUT presumed minor/caneling/merely pecuniary\n", "       1. wages might rise in poor countries\n", "       1. wages might fall in rich countries\n", "       1. returns to other factors (capital) might rise in rich countries\n", "       1. returns to other factors (capital) might fall in poor countries\n", "       1. Not all externalities deserve a \"pigovian tax\"\n", "           1. smoke stacks yes; price/wage changes *no*\n", "   1. lots of models with production functions; general equilibrium & etc \n", "\n", "### A smaller but livlier version of Clemens' figure 1\n", "\n", "<a href=\"https://shiny.demog.berkeley.edu/carlm/EconImmig0/\" target=\"_new\"> Neoclassical model of wage effects of immigration</a>\n", "\n", "\n", "\n", "<img src=\"https://courses.demog.berkeley.edu/mason88/images/clemensFig1.png\">\n", "\n"]}, {"cell_type": "code", "execution_count": null, "source": ["# Run this cell to import the stuff we'll need\n", "import pandas as pd\n", "import numpy as np\n", "import scipy as sp\n", "import matplotlib.pyplot as plt \n", "import gc\n", "#plt.style.use('fivethirtyeight')\n", "\n", "%matplotlib inline\n", "from datascience import Table\n", "from datascience.predicates import are\n", "from datascience.util import *\n", "\n", "from IPython.display import HTML, IFrame, display\n", "datasite=\"https://courses.demog.berkeley.edu/mason88/data/\"\n", "quizsite=\"https://courses.demog.berkeley.edu/mason88/cgi-bin/quiz.py\"\n", "  \n", "def cquiz(qno) : \n", "    import IPython, requests \n", "    try:\n", "        sid\n", "    except NameError: \n", "        print(\"HEY! did you enter your sid way up at the top of this notebook?\")\n", "    Linkit='{0}?qno={1}&sid={2}'.format(quizsite,qno,sid)\n", "    #print(Linkit)\n", "    html = requests.get(Linkit)\n", "    #display(IFrame(Linkit, 1000, 300))\n", "    display(IFrame(Linkit, 1000, 400))\n", "\n", "\n", "    \n", "######################\n", "# Here it is ... the obvious place to put your student id\n", "sid=\"\"\n", "######################\n", "if sid == \"\" :\n", "    print(\"HEY! didn't I tell you to put your sid in the obvious place\")\n", " \n"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["### #### #### ####\n", "###  SELECTING  LAB  PARTNERS\n", "### ### #### ####\n", "\n", "N=8\n", "numbers=np.arange(N)\n", "print(np.mod(N,2))\n", "if (not np.mod(N,2) == 0) :\n", "    numbers=np.append(numbers,\"lucky\")\n", "    N+=1\n", "numbersTab=Table().with_column('n',numbers)\n", "randomized=numbersTab.sample(k=N,with_replacement=False)\n", "selection=randomized['n']\n", "selection.shape = (2,int(N/2))\n", "Table().with_columns('zero',selection[0],'one',selection[1]).show()"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["cquiz('wage01-partners')\n"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## The data for this week\n", "\n", "1. Residents of California, New York, Illinois, or Texas In 2000 and 2015\n", "1. Ages grouped by age and time 25-30 yrs old (in 2000) vs 40-45 (in 2015)\n", "1. Immigrants who arrived at ages 20-25\n", "1. productivity = Total Annual Wages/(usual hr per week * weeks worked last year) \n", "1. educ4 = education level coded into 5 mutually exclusive groups\n", "1. Data come from American Community Survey via IPUMS\n", "1. Data include weights which we must use.\n", ">Steven Ruggles, Katie Genadek, Ronald Goeken, Josiah Grover, and Matthew Sobek. Integrated Public Use Microdata Series: Version 6.0 [dataset]. Minneapolis: University of Minnesota, 2015. http://doi.org/10.18128/D010.V6.0.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "source": ["# Read the data and examine the columns\n", "\n", "wg=Table().read_table(datasite+'earnings2015new.csv')\n", "## changing 'immig' to string instead of logical\n", "wg.append_column('immig',['immigrant' if im else 'USborn' for im in wg['immig']])\n", "## adding a column \"age\" to avoid clumsy typing\n", "wg.append_column('age',['old' if a > 35 else 'young' for a in wg['AGE']])\n", "wg.where('immig','immigrant').where('YEAR',2000).show(10)\n", "wg.where('immig','USborn').where('YEAR',2000).show(10)\n", "wg.where('immig','immigrant').where('YEAR',2015).show(10)\n", "wg.where('immig','USborn').where('YEAR',2015).show(10)"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## Cleaning up the birth place variable\n", "\n", "#### with a very useful python trick"]}, {"cell_type": "code", "execution_count": null, "source": ["## tidy up the 'bpl'  variable --with a clever python trick\n", "bpl_modified=['USA' if w['immig'] == \"USborn\" else w['bpl'] for w in wg.to_array()]\n", "\n", "wg.append_column('bpl',bpl_modified)\n", "## tidy up immig variable no fancy trick needed\n", "\n", "wg.pivot('immig','bpl').sort('USborn',descending=True)"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## Before we proceed with science, let's discuss the strengths and weaknesses of the data.\n", "\n", "1. Did the world change between 2000 and 2015 ?\n", "1. Are we observing the same people in 2000 and 2015 ?\n", "1. Are five year age categories ideal ?\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Productivity measure\n", "\n", "Clemens refers to productivity without defining it.  Which is reasonable because economists all know what it means: productivty = output/unit of input. Since the input is labor, Clemens is talking about *output per unit of labor* To confuse matters further, in figure 1,  includes **not** productivity but rather two *demand curves for labor* (one for rich countries the other for poor countries).\n", "\n", "productivity and demand for labor are linked by the \"fact\" that in a perfect market, the *marginal productivity of labor = the wage*. Thus wages are the key to everything. AND wages are  *theoretically* the productivity of the last worker hired aka the \"margingal productivity of labor\". \n", "\n", "We should perhaps discuss this in class.\n", "\n", "Having convinced ourselves of the above economics \"fact\" we can compute a measure of *marginal productivity* of various sources of labor--which is *sort of* what Clemens is talking about."]}, {"cell_type": "code", "execution_count": null, "source": ["# computing productivity\n", "wg.append_column('prod',wg[\"INCWAGE\"]/(wg[\"UHRSWORK\"]*wg[\"wkswork\"]))\n", "\n", "wg.select(['age','immig','prod'])\n"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## Digression on PERWT \n", "\n", "The marginal productivity numbers that we just computed are nice BUT as respectable data scientists, we must take note of the following:\n", "\n", "* These data comprise a structured random sample rather than a \"simple\" random sample, and thus it is <b> essential that we take account of weights</b> if we ever want to publish our results.\n", "    \n", "*  In the Great Migration labs, recall that when working with sums, it was proper to divide by .05 since the sample was a 5% simple random sample. Another way of thinking about that is that each observation in that Great Migration lab sample represented 20 people in the US in 1960.  Consequently, giving each observation a \"weight\" of 20 was appropriate in all computations.  Because *all* observations had a weight of 20, it was not necessary to explicitly include the weights when computing means -- because all those 20s would just cancel out.  NOT SO THIS TIME.\n", "\n", "*  In *this* data set, sampling was done according to a complicated set of rules that ensured that the sample would have much broader coverage in terms of geography and ethnicity than would a simple random sample of the same size.  The price we pay for that is that we must take weights into account *even when computing means*. While in the Great Migration sample, all weights were \"20\"  in this sample, the weights are stored in 'PERWT' and the variation across individuals is considerable."]}, {"cell_type": "code", "execution_count": null, "source": ["# Since the data from 2000 are drawn from a 5% sample, most observations have weights around 20 however, \n", "# the data from 2015 are a 1% sample so many observations should have weights of around 100 ... and of course,\n", "# there are a few that are way out there.\n", "\n", "print(wg.select(\"PERWT\").stats())\n", "wg.select('PERWT').hist(bins=100)"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["#### So we can improve our measure of marginal productivity by using  *weights*\n", "\n", "\n", "Weighted means are not hard to compute, but it involves an extra step. The formula is:\n", "\n", "$$ \\text{Weighted mean} = \\frac{\\sum_{i=1}^{N}{x_iw_i}}{\\sum_{i=1}^{N}{w_i}}$$\n", "\n", "where $x_i$ is the $i^{th}$ observation of the variable that you are taking the weighted mean of, and $w_i$ is the weight corresponding to the $i^{th}$ observation. In our present case, $x$ is a measure of productivity and $w$ is 'PERWT'.\n", "\n", "Actually, owing to the limitations of the Tables.group method, computing the weighted means also require some extra python -- which slows things down a bit.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Computing the weighted mean of productivity\n", "\n", "Fill in the ???"]}, {"cell_type": "code", "execution_count": null, "source": ["## The weighted mean of \"productivity\"\n", "'''\n", "## The hard way:\n", "hardway=np.sum(wg[???]*wg[???]/np.sum(wg[???]))\n", "## The easy way:\n", "easyway=np.average(wg['prod'],weights=wg['PERWT'])\n", "print(\"hardway: {0}  easyway: {1}\".format(hardway,easyway))\n", "'''"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## But what does  27.196  tell us?\n", "\n", "The weighted mean productivity of what ? "]}, {"cell_type": "code", "execution_count": null, "source": ["# computing weighted productivity for groups whose wtd productivity we wish \n", "# to compare\n", "pdict=dict()\n", "for a in ['young','old']:\n", "    for i in ['immigrant','USborn'] :\n", "        # create a table that is a subset of wg\n", "        temp=wg.where(\"immig\",i).where(\"age\",a)\n", "      \n", "        easy=np.average(temp['prod'],weights=temp['PERWT'])\n", "      \n", "        pdict[(i,a)]=easy\n", "\n", "        \n", "print(pdict)"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["## Note that pdict is a dictionary ... not a table this means that we\n", "## can reference individual cells much more easily e.g.:\n", "pdict['USborn','old']"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## What conclusions might we draw from weighted means of marginal productivities?\n", "\n", "#### Are \"old\" immigrants in 2015  more disadvantaged relative to USborns than are \"young\" immigrants in 2000 ?\n", "\n", "#### Consider this statistic :\n", "\n", "$$ \\frac{\\text{prod}_{\\text{immig,old}}}{\\text{prod}_{\\text{immig,young}}}/  \\frac{\\text{prod}_{\\text{USborn,old}}}{\\text{prod}_{\\text{USborn,young}}} $$\n", "\n", "Can we justify the above statistic as an estimate of the degree to which immigrants lose(gain) ground (in relation to USborn wages) with experience in US labor markets?\n"]}, {"cell_type": "code", "execution_count": null, "source": ["\n", "\n", "(pdict['immigrant','old']/pdict['immigrant','young'])/\\\n", "    (pdict['USborn','old']/pdict['USborn','young'])"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## Well that looks like the answer ... \n", "\n", "####  What does 0.844 mean  ?\n", "\n", "So based on the above analysis,  we are have a result that indicates that overall, immigrants tend to become less productive relative to US born workers as they gain experience in the US labor market?  Is it just me, or does that also strike you as odd?  Many immigrants arrive in the US unable to speak english and without much in the way of job networks or experience with US work place norms.  Could language skills and experience in the US really make immigrants *less* productive ?\n", "\n", "Really ?  Let's discuss this in class "]}, {"cell_type": "markdown", "metadata": {}, "source": [" ## And what about uncertainty ?\n", " \n", " ##### Could this 0.844 be a chance event due to random sampling?\n", " \n", "\n", "#### Do I hear you crying out for a simulation?  or what ?\n", " \n", "In previous labs, the null hypothesis was that random chance alone explained the difference between the observed and expected quantities.  That allowed us to construct a model of the null hypotesis based on random sampling which could show us how life would be if the null hypothesis were indeed operating.\n", "\n", "It's a little bit different in the present case.  \n", "\n", "* What is the null hypothesis in this case?\n", "* What is the source of random error ?\n", " \n", "### What can we do?"]}, {"cell_type": "markdown", "metadata": {}, "source": [" 1. Write a function that computes the ratio-of-ratios statistic from a sample of wg records\n", " 1. Write a loop that draws a sample; calls the function to compute statistic; stores result\n", " 1. Interpret result"]}, {"cell_type": "code", "execution_count": null, "source": ["# A Function that computes statistic\n", "def getStat(wg=wg) :\n", "    res=dict()\n", "    for a in ['old','young']:\n", "        for i in ['immigrant','USborn'] :\n", "            # create a table that is a subset of wg\n", "            \n", "            temp=wg.where(\"immig\",i).where(\"age\",a)\n", "\n", "            easy=np.average(temp['prod'],weights=temp['PERWT'])\n", "            # store result in dictionary indexed by tuple so we can use it later\n", "            res[(i,a)]=easy\n", "    # compute diff in ratio statistic        \n", "    return((res['immigrant','old']/res['immigrant','young'])/\\\n", "           ( res['USborn','old']/res['USborn','young']))"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["\n", "##### Write loop that..\n", "# draws samples; computes and stores the statistic for each sample\n", "##\n", "bs=[]\n", "for n in np.arange(10):\n", "    # note end='\\r'  this will address our impatience.\n", "    print('sampling iteration: {0}'.format(n),end='\\r')\n", "\n", "    \"bs.append(getStat(?????))\"\n"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["### Interpret the result\n", "\n", "Table().with_columns('bs',bs).hist()\n", "plt.scatter(np.percentile(bs,[5,95]), [0,0], color='red', s=30)\n", "plt.scatter(getStat(wg),0 ,color='blue',s=30)\n", "plt.xlabel('Simulated statistic')"], "outputs": [], "metadata": {"scrolled": true}}, {"cell_type": "markdown", "metadata": {}, "source": ["###  Do you think education matters ?\n", "\n", "do wages of immigrants with more or less education catch up faster to non-immigrants with similar education levels?\n", "\n", "Let's do the analysis separately by education level"]}, {"cell_type": "code", "execution_count": null, "source": ["\n", "#Important Cell: Educaiton \n", "## store results of bootstrap\n", "bs=dict()\n", "stat=dict()\n", "for cat in np.unique(wg['educ4']) :\n", "    bs[cat]=[]\n", "    # subsample of data for analysis\n", "    temp=wg.where('educ4',cat)\n", "    # observed stat\n", "    stat[cat]=getStat(temp)\n", "    ## do some bootstraps ... more is better\n", "    for n in np.arange(10):\n", "        print('sampling iteration category ={0}: {1}'.format(cat,n),end='       \\r')\n", "        bs[cat].append(getStat(temp.sample()))\n", "\n", "# show results        \n", "for cat in bs.keys():\n", "    \n", "    Table().with_columns(cat,bs[cat]).hist()\n", "    plt.scatter(np.percentile(bs[cat],[5,95]), [0,0], color='red', s=30)\n", "    plt.scatter(stat[cat], 0,color='black', s=30)\n", "    plt.title(\"\")\n"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## On your own ...\n", "\n", "So we have learned that the trajectory of economic assimilation of immigrants is complicated. Overall, since 2000 we found that immigrants *fell behind US born workers* in that the wage gap between young newly arrived immigrants and similarly aged US borns in 2000 was _*smaller*_ than the corresponding ratio for older immigrants and US borns in 2015. \n", "\n", "\n", "But if we run the analysis on subsamples based on education, there is a hint that those with more education fared a bit better -- but the real losers are those with a high school degree.\n", "But it's not perfectly clear because as the sample sizes get smaller, the uncertainty increases. \n", "\n", "Question: Does this mean that people without a high school degree did better than those with a diploma?\n", "\n", "\n", "The final exercise in this lab is to run the same bootstrap analysis as we did for education ... for the four largest immigrant groups.  That is, run the same bootstrap code as we did in \"Important Cell: Eduation\" BUT subset the data by country of origin rather than by education level.  \n", "\n", "\n", "You'll do this by copying the \"Important Cell: Education\" and modifying it so that it selects subsets that include only those who were born in a particular country AND those who were born in the US. \n", "\n", "The cell below will help you find the four largest immigrant sending countries.\n", "\n", "\n", "\n", "Hints:\n", " - You only need to copy and modify the cell called \"Important Cell: Education\".\n", " - Test your code running only 2 bootstraps for each coutry of origin -- but once it works, run 100 trials on each (get coffee).\n", " - The cell below can inform us as to which are the largest origin countries of US immigrants.\n", " - The cell below the cell below has some code snippets that you are very likely to find helpful"]}, {"cell_type": "code", "execution_count": null, "source": ["# this is the \"cell below\"\n", "# which are the four largest countries of origin?\n", "\n", "wg.where('immig', 'immigrant').group('bpl').sort('count',descending=True)"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["## this is the \"cell below the cell below\"\n", "## Could be useful .. check this out\n", "\n", "foo=wg.where('bpl','China').with_rows(wg.where('bpl','USA').to_array())\n", "foo.group('bpl')"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["cquiz('wage01-prod')"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["cquiz('wage01-ratrat')"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["cquiz('wage01-bs')"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["cquiz('wage01-bias')"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["cquiz('wage01-adjusted')"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "metadata": {}, "source": ["## That is for Lab 7\n", "\n", "###  Please take the trouble to evaluate so that next year's students' sufferring can be reduced."]}, {"cell_type": "code", "execution_count": null, "source": ["cquiz('wage01-eval')"], "outputs": [], "metadata": {}}]}