{"cells": [{"metadata": {}, "source": ["Demography 88<br>\n", "Fall 2019<br>\n", "Carl Mason (cmason@berkeley.edu)<br>\n", "##  The Great Migration : Clarksdale (part 1)\n", "\n", "#### Goals for this week:\n", "\n", "1. To examine conditions and characteristics of Black and White Americans in the South to validate / corroborate what we read in Lemann.\n", "\n", "2. To develop statistics that quantify the discrimination  to which Black Americans in the South were subject in 1960. Discrimination is not easily measured as it has a lot to do with what is in people's brains and the US Census is far too cowardly to try to measure that directly.\n", "\n", "3. To quantify the uncertainty due to sampling around our estimates of discrimination\n", "\n", "\n", "This week the plan is to use data from the 1960 Census to investigate/illustrate Nicholas Lemann's description of life in the US South in the middle of the 20th Century. Even to those who have not read the Clarksdale chapter of <i>Promised Land</i> (of whom there are none among us) -- it will come as no surprise that Black Americans in the US South endured inequality in virtually every sphere of life.  The fact that this is well known should not deter the young data scientist from further explortion.\n", "\n", "In the *next*  lab on the Great Migration,  we will take a look at the characteristics of those who chose to migrate from the south to the north.  Keep that in mind as we investigate conditions in the South because the obvious question that you might be asked is whether the people who sufferred most were the most likely to leave.\n", "\n", "The Census data that we are using today comes to us via the Integrated Public Use Microdata Series project at the University of Minnesota Population Center. [http://ipums.org] is a fantastic resource containing not only census data but also data from many other sources both US and from other countries -- all of it carefully harmonized to make the data as comparable as possible. Here's the official citation:\n", "\n", ">Steven Ruggles, Katie Genadek, Ronald Goeken, Josiah Grover, and Matthew Sobek. Integrated Public Use Microdata Series: Version 6.0 [dataset]. Minneapolis: University of Minnesota, 2015. http://doi.org/10.18128/D010.V6.0.\n", "\n", "## Some important notes about the data we are going to use today:\n", "\n", "#### While the US Census is a complete enumeration, what the IPUMS distributes is not.  In order to save (a lot of money) IPUMS draws a random sample of 5 percent of households (this is done with the manuscripts of the ancient census returns, of course,  but it functionally the same as if they had selected the dwelling units).  By randomly selecting *households*  rather than *individuals*,  much more useful information is available to us -- things like number of siblings in a household; the characteristics of parents *and* children together; characteristics of dwelling units; and the relationship among people who share a dwelling.\n", "\n", "#### It is worth keeping this in mind as you ponder your final project, as this sort of data is available from IPUMS for lots of times and places.  As is typical for census data from IPUMS, each row of the table that we read in, will refer to an individual -- it will contain information on lots of things pertaining to that individual, for example,  sex, age, wage income, and education.  Each row also contains a variable called \"SERIAL\"  this number uniquely identifies households.  Groups of rows of the table with the same value of SERIAL, are households.  Each person within such a household has a unique PERNUM value which starting with 1.  Within each household, PERNUM is unique for each individual while SERIAL is the same.  All household level variable e.g. dwelling unit characteristics,  will be the same for all members of the household.\n", "\n", "#### In this particular sample (1960, 5 percent) simple random sampling is used -- consequently,  as we noted in the Fertility lab,  this is not always the case with IPUMS.  But this time it is, so we need not worry about weights -- except when we wish to present estimates for the entire population.  If we wanted, for example to know the number of 13 year olds in the population,  we would count them up in our sample and then divide that sum by .05 (or multiply it by 20  whatever).\n", "\n", "## Put your student id in the obvious place and then run the cell below"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["# Run this cell to import the stuff we'll need\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt \n", "#plt.style.use('fivethirtyeight')\n", "\n", "%matplotlib inline\n", "from datascience import Table\n", "from datascience.predicates import are\n", "from datascience.util import *\n", "from IPython.display import HTML, IFrame, display\n", "datasite=\"https://courses.demog.berkeley.edu/mason88/data/gmig0/\"\n", "quizsite=\"https://courses.demog.berkeley.edu/mason88/cgi-bin/quiz.py\"\n", "  \n", "def cquiz(qno) : \n", "    import IPython, requests \n", "    try:\n", "        sid\n", "    except NameError: \n", "        print(\"HEY! did you enter your sid way up at the top of this notebook?\")\n", "    Linkit='{0}?qno={1}&sid={2}'.format(quizsite,qno,sid)\n", "    #print(Linkit)\n", "    html = requests.get(Linkit)\n", "    #display(IFrame(Linkit, 1000, 300))\n", "    display(IFrame(Linkit, 1000, 400))\n", "\n", "\n", "    \n", "######################\n", "# Here it is ... the obvious place to put your student id\n", "sid=\"\"\n", "######################\n", "if sid == \"\" :\n", "    print(\"HEY! didn't I tell you to put your sid in the obvious place\")\n", " \n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## And as usual indicate with whom you are working this week"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["cquiz('greatMig0-partners')\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["# Background on African American Migration\n", "\n", "1. African American History can be told (well oversimplified) as the story of three migrations\n", "    1. The \"Middle Passage\"\n", "    1. The 19th Century migration from the old (tobacco) South to the \"new' (cotton) south\n", "    1. The 20th Century \"Great Migration\" from the rural South to the urban North between 1917 and 1970\n", "    "], "cell_type": "markdown"}, {"metadata": {}, "source": ["#  Antebellum Slavery\n", "\n", "1. Cotton is the big story\n", "   1. Makes \"short staple\" cotton profitable opens up vast territory for cotton cultivation\n", "   1. BAD news for Native Americans who occupy much of that land by treaty\n", "   1. BAD news for enslaved Americans who will move in large numbers onto cotton plantations\n", "   \n", "   1. Cotton is hugely important crop for Industrial Revolution\n", "       1. 80% of British imports from US South on eve of Civil War\n", "       1. Also key to industrialization in New England\n", "     \n", "   \n", "   "], "cell_type": "markdown"}, {"metadata": {}, "source": ["# The 18th Century view of slavery and the Civil War\n", "\n", "1. Slavery was morally wrong and therefore inefficient\n", "1. slavery was demographically doomed\n", "    1. Limited amount of land where slave agriculture is profitable\n", "    1. Population grows as Malthus would want it to \n", "        ==> too many slaves not enough land\n", "        ==> cheaper to hire workers at subsistence wage\n", "\n", "1. Cotton Gin expanded area of cultivation OUCH!\n", "1. Big unsettled question whether technology was improving efficiency of slave ag.\n", "1. By 1850s the issue is the colonies (\"territories\"). \n", "   1. Imperative for anti-slavery folks, to keep slavery out of territories. \n", "   1. Equally imperative for pro-slavery to open new lands.\n", "   \n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["# Reconstruction\n", "\n", "1. The end of the Civil War brought emancipation but no 40 acres and no mule\n", "    1. Self sufficiency was not widely possible for freed slaves see above (and Lemann)\n", "    1. New methods of social control and labor exploitation develop\n", "  \n", "    "], "cell_type": "markdown"}, {"metadata": {}, "source": ["<img src=\"http://courses.demog.berkeley.edu/mason88/images/Census_1900_Percent_Black.png\">"], "cell_type": "markdown"}, {"metadata": {}, "source": ["## The US South in 1960\n", "\n", "By 1960, much of the Great Migration has already run its course.  The migration began around 1917 with US involvement in WWI and by the 1970s the general move towards the \"Sun Belt\" overwhelms what's left of the Great Migration and the net migration pattern of Black Americans turns southward.  But the reverse great migration is different in many respects from the north to south flow -- most importantly the reverse flow was (and is) and urban to urban migration whereas much of the Great Migrations was rural to urban.\n", "\n", "Today the proportion of African Americans who live in the South (~ 55%) is close to what it was in 1960 (~60%).  So while the pioneers of the Great Migration  established themselves in the North decades earlier,  the population of the South was still experiencing natural growth and still sending considerable numbers of people north.\n", "\n", "This week, to add interest, we can each choose a southern state at random for analysis.  The structure of each state\n", "data file is the same, but presumably some of the values and results will be somewhat different. Doing state level analyses will also speed us along by keeping our data sets to a manageable size. Since the state data files are identically structured, code written for any state will work on any other-- so even though you and your partner may be working on different states, you can still share code snippets without any difficulty.\n", "\n", "\n", "\n", "### Read some data and develop some code to compare the positions Black and White Americans"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["## Read a file that contains the names of all the state level data sets\n", "files=Table().read_table(datasite+'States1960.csv')\n", "## choose a file at random\n", "print(\"Pick one state at random from this list\")\n", "files.show()\n", "randomState=files.sample(k=1)[1][0]\n", "\n", "print(\"Reading data for :\"+randomState)\n", "## read the date corresponding to the state that fate has determined that you should know more about\n", "###\n", "# NOTE -- after reading a state1960.csv file one time, you may uncomment and modify the following line to\n", "# make sure that you read that same (randomly assigned) state in subsequent sessions.  It is helpful to do this\n", "# if you don't have enought time to do the entire lab in one sitting  OR if you are prone to having your\n", "# notebook restart for want of RAM\n", "\n", "# randomState=\"??????1960.csv\"\n", "st60=Table().read_table(datasite+randomState)\n", "st60.show(5)\n", "print(\"number of rows: {} \".format(st60.num_rows))\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## Let's explore the data\n", "\n", "with some summary statistics and cross tabs\n", "\n", "list(st60) gives us a list of column names in the st60 table. Note that some are lower case and others are UPPER case.  Variables in lower case are those that your instructor has cleaned up -- generally these are categorical  variables  and your instructor has changed number codes in the original file to more informative text strings.  The variables in UPPER CASE are straight from the IPUMS data file, UPPER case variables are always numbers but the information that they represent is not always numerical for example, SERIAL is a numerical identifier that is unique for each household, but the number itself has no significance.\n"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["# A list of variables\n", "list(st60)\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["# Cross tabulations and summary statistics\n", "\n", "In the next few cells, we'll develop some functions that will help us explore the data. We'll use a tiny bit of pandas but once again, for this class, knowing how to *use* the functions is what's important. \n", "\n", "We'll deal with continuous and categorical variables separately. The immediate goal is to create some functions that will show us differences in socio-economic sorts of measures between Black and White Americans in the US South in 1960."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["# a function to produce a one way frequency table of a categorical \n", "# variable\n", "def pfreq(vname,data=st60):\n", "    \"\"\"\n", "    expects a categorical col from a table; returns frequency dist.\n", "    Mostly this will be called by other functions\n", "    \"\"\"\n", "\n", "    df = pd.Series(data[vname]).value_counts()\n", "    res=df/len(data[vname])\n", "    result=Table().with_column(vname,res.index).with_column('value',res.values)\n", "    \n", "    return(result)\n", "    #return(df/len(var))\n", "\n", "\n", "    "], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["# One way frequency distribution aka \"empirical distribution\" of \n", "# employment status\n", "pfreq('empstat')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["pfreq('relate')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["### disagregating by race\n", "\n", "Since our focus is on discrimination, we'll generally want to look variables like 'empstat' *disagregated* by race.  Let's develop a function that does that.\n"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["# uses pfreq to produce empirical distributions disagregated by\n", "# race -- or some other variable if desired\n", "\n", "def byraceCAT(vname,data=st60,byvar='race'):\n", "    \"\"\"\n", "    expects a table with at least 2columns vname -- the column of \n", "    interest,  byvar (deaults to 'race') is the column by which \n", "    frequencies shall be disagregated and displayed\n", "    \"\"\"\n", "    vcats=np.unique(data[vname])\n", "    for r in np.unique(data[byvar]):\n", "        #print('\\n'+ r + ':\\n')\n", "        res=pfreq(vname,data.where(byvar,r)).relabeled('value',r)\n", "        for vc in vcats :\n", "            if vc not in res[vname]:\n", "                res.append(Table().with_columns(vname,vc,r,0))\n", "        try :\n", "            result\n", "            result=result.join(vname,res)\n", "        except NameError:\n", "            result=res\n", "            \n", "   \n", "    return(result)"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["byraceCAT(vname='empstat')\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["## We can capture the output of byraceCAT as a table\n", "edRace=byraceCAT('edyears')\n", "edRace.show()"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": [], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["byraceCAT('edyears',byvar='labforce')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["def byraceCON(vname,byvar='race',data=st60):\n", "    \"\"\"\n", "    expects variable name byvar and data produces descriptive stats of\n", "    vname disagreaged by byvar which must be columns of data (table)\n", "    \"\"\"\n", "    result=Table().with_column('Statistic',[\"N\",\"mean\",\"median\",\"std\",\"min\",\"max\"])\n", "    for r in np.unique(data[byvar]):\n", "       \n", "        pds=pd.Series(data.where(byvar,r)[vname])\n", "        res=[pds.count(),pds.mean(),pds.median(),pds.std(),pds.min(),pds.max()]\n", "      \n", "        result=result.with_column(r,res)\n", "    return(result)    "], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["byraceCON('CHBORN').show()\n", "# once again limiting the input data can produce more meaningful results\n", "byraceCON('CHBORN',data=st60.where('AGE',are.between(15,45)).where('sex','Female'))"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["byraceCON('incwage').show()\n", "byraceCON('incwage',data=st60.where('edyears',12))"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## Graphs ... yes graphs are useful in our search for evidence of discrimination.\n", "\n", "Graphs are especially useful when there are a large number of categories (e.g. edyears) or a continuous variable (e.g. AGE) across which we want to compare vaues corresponding to Black and White Americans.  We'll make user of the .groups() method to draw graphs.\n", "\n", "Since many determinants of socioeconomic status *should* vary with age and experience, inequality *within* age categories is more informative with respect to discrimination.  Age lends itself quite well to the x-axis\n", "\n", "Let's compare income by age by drawing some scatter plots with AGE on the x axis and with separate dots for White and Black averages. "], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["## INCOME\n", "# edyears = years of education\n", "## a table of mean years of education by race and age\n", "\n", "## THIS is the important line of code -- using .groups()\n", "incwageA=st60.select(['AGE','race','incwage']).\\\n", "    groups(['AGE','race'],collect=np.nanmean)\n", "# here is what the result looks like\n", "incwageA.where('AGE',are.between(15,20)).show()\n", "## clean up variable names\n", "incwageA.relabel('incwage nanmean','WageIncome')\n", "\n", "## use the datascience package method for scatter plot\n", "incwageA.scatter('AGE','WageIncome',colors='race')\n", "plt.title(\"Income v Age\")\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## Why might a careful scientist (with no knowledge of the history or race in the US *not* accept this as evidence of *discrimination*?\n", "\n", "It ***definitely shows difference*** but is wage inequality per se proof of discrimination?\n", "\n", "### Enlightening discussion ensues\n", "\n", "\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["#### Consider the graph below"], "cell_type": "markdown"}, {"metadata": {"scrolled": true}, "execution_count": null, "source": ["## Education\n", "# edyears = years of education\n", "## a table of mean years of education by race and age\n", "\n", "## THIS is the important line of code -- using .groups()\n", "edyearsP0=st60.select(['AGE','race','edyears']).groups(['AGE','race'],collect=np.nanmean)\n", "# here is what the result looks like\n", "edyearsP0.where('AGE',are.between(25,30)).show()\n", "## clean up variable names\n", "edyearsP0.relabel('edyears nanmean','YearsEducation')\n", "\n", "## use the datascience package method for scatter plot\n", "edyearsP0.scatter('AGE','YearsEducation',colors='race')\n", "plt.title(\"Education v Age\")\n", "edyearsP0.where('AGE',are.not_above(20)).scatter('AGE','YearsEducation',colors='race')\n", "plt.title(\"Closeup of early ages\")"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## OK is that sufficient ?\n", "\n", "\n", "How about taken together the graphs of wage income v age and education v age... is that discrimination?\n", "\n", "Once again, knowing what we do about race in America, it is very hard to insist --in the face of these graphs -- that your state's labor market and education systems were color blind.  But ...\n", "\n", "\n", "## Pause for further discussion"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["## How about income by years of education...\n", "incwageEd=st60.where('labforce','Yes, in the labor force').\\\n", "    where('sex','Male').\\\n", "    select(['race','edyears','incwage']).\\\n", "    groups(['race','edyears'],collect=np.nanmean)\n", "\n", "##  cleanup by relabeling the column of interest\n", "incwageEd.relabel('incwage nanmean','WageIncome')\n", "# take a look at the table we just built\n", "incwageEd.show(5)\n", "# and make some graphs\n", "incwageEd.scatter('edyears','WageIncome',colors='race')\n", "plt.title(\"Wage income by years of education\")\n", "##"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["# And finally ... income by age within education levels disagregated by race\n", "\n", "The graphs of wage income by age and by edyears are pretty compelling, but we can put a yet finer point on it by considering age.  Over the life course, a person with a given level of education should see some wage growth as she gains experience. If workers of different race/education groups have different age profiles ... that could be gumming things up.  \n", "\n", "Is it likely that age could produce the pattern we just saw?  Probably not but as demographers, we must press on regardless."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["## plot incwage by age,education and race \n", "\n", "## include only laborforce participants\n", "## group by age,race and edyears\n", "# make a table of mean incwage by age and race.\n", "\n", "incwageP0=st60.where('labforce','Yes, in the labor force').\\\n", "    where('AGE',are.between(16,64)).\\\n", "    where('sex','Male').\\\n", "    select(['AGE','race','edyears','incwage']).\\\n", "    groups(['AGE','race','edyears'],collect=np.nanmean)\n", "\n", "##  cleanup by relabeling the column of interest\n", "incwageP0.relabel('incwage nanmean','WageIncome')\n", "# take a look at the table we just built\n", "incwageP0.show(5)\n", "# and make some graphs\n", "incwageP0.where('edyears',are.between_or_equal_to(0,9)).scatter('AGE','WageIncome',colors='race')\n", "plt.title(\"0-9 years of education\")\n", "##\n", "incwageP0.where('edyears',are.between_or_equal_to(9,11)).scatter('AGE','WageIncome',colors='race')\n", "plt.title(\"9-11 years of education\")\n", "\n", "##\n", "incwageP0.where('edyears',12).scatter('AGE','WageIncome',colors='race')\n", "plt.title(\"12 years of education\")\n", "##\n", "incwageP0.where('edyears',are.above(12)).scatter('AGE','WageIncome',colors='race')\n", "plt.title(\"more than 12 years of education\")\n", "#edyearsP0.where('AGE',are.not_above(20)).scatter('AGE','WageIncome',colors='race')\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["##  call smallScatter with interesting subsets of educaiton levels\n", "print(\"Just people who have NOT graduated high school\")\n", "smallScatter(st60.where('edyears',are.below_or_equal_to(11)))\n", "## In order to answer the next question, you will need to produce scatter plots like\n", "## this one for high school graduates (edyears == 12)  and for those with \n", "## some college (edyears > 12)\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["##  Housing conditions\n", "\n", "Since, as we have seen, Blacks are being paid on the order of half as much as whites with similar education and experience,  we should expect that most Black southerners will live in less desirable housing than White southerners. \n", "\n", "We can see that for example in the number of rooms per household:\n"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["# just use ONE record per household \n", "rooms=st60.where('PERNUM',1).pivot('ownership','race',values='rooms',collect=np.nanmean)\n", "## Creat a function to compute household size\n", "def mnunique(x) :\n", "    'return the mean number of unique elements -- used with SERIAL to count hh members'\n", "    unique_elements, counts_elements = np.unique(x, return_counts=True)\n", "    return(np.mean(counts_elements))  \n", "# just use ONE record per household \n", "hhsize=st60.pivot('ownership','race',values='SERIAL',collect=mnunique)"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["print(\"Rooms per house\")\n", "rooms.show()\n", "print(\"People per house\")\n", "hhsize.show()"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## Consider a more stringent definition of discrimination\n", "\n", "As we saw with education and income, discrimination is surely there but given the more complicated the system and markets involved, the harder it is to separate discrimination from mere difference.  The housing market is a little less complicated than the labor market and education systems so we can take our analysis a little further.\n", "\n", "Let's consider as a  definition of discrimination -- such as one might encounter in an economics department: \n", "\n", "If we take as given the \"initial endowment\" (i.e. we don't consider the reasons why some people are poorer than \n", "others) we might call it discrimination only when people with the same resources face different constraints due some unrelated characteristic.\n", "\n", "To investigate this sort of thing, let's use the variable rentDecile -- which is one that your instructor built -- it breaks renters up into deciles (e.g. 10th percentile, 20th percentile ...) so a value of \"30\" for example means that the household's gross rent is higher than 30% of all renting households. To be more precise households whose rent is in the 30th to 39.9999th percentile of rents will have a rentDecile value of 30. \n", "\n", "We can use the rentDecile variable along with some housing characteristics to look for evidence of discrimination in the rental housing market. \n", "\n", "### NOTE that in the code below, we have to limit our computation to  observations where \"PERNUM\" == 1.  PERNUM is just an index number within each household.  Every household has a person whose PERNUM ==1, because every household has at least one person in it.  By limiting our data to one person per household, we are effectively looking at households rather than people.  That's a good thing because otherwise we would over count houses with more people in them."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["# Cost per room by rent decile disagregated by race\n", "\n", "roomcost=st60.where('PERNUM',1).where('rentDecile',are.above(0)).\\\n", "select(['rentDecile','race','rooms']).groups(['rentDecile','race'],collect=np.nanmean)\n", "roomcost.show()\n", "roomcost.scatter('rentDecile','rooms nanmean',colors='race')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## How about uncertainty ?\n", "\n", "Once again, we must remind ourselves that we are working with a random sample and as such, any conclusions we might wish to draw--about the underlying universe (i.e. some southern state in 1960), are subject to many kinds of uncertainty. Some sources of uncertainty e.g. bias among census enumerators -- we have no way of addressing. One important kind of uncertainty that we can address is sampling uncertainty.  \n", "\n", "Suppose for example that after all this computation, we find, that in Tennesee in 1960 the IPUMS sample reveals that among households paying about the median rent (rentDecile = 50) -- those households headed by white people enjoy an average of 3.8 rooms while black households on average have only 3.32 **(If your state is NOT Tennesee, you are probably NOT seeing these numbers in the graphs that you produced above.)**\n", "\n", "Although there is plenty of room to quibble, a reasonable person might argue that the ratio of these two number 3.32/3.80 = 0.87 is a measure of discrimination that even an economist ought to accept.  We are comparing Black and White households **who are paying about the same amount of money for rent** and we are observing that **Black headed households get fewer rooms.** Let's call this ratio the Black-White room ratio (BWRR).\n", "\n", "Again quibbling is possible (Let's do that in class)  But if we accept that the BWRR at least plausibly quantifies discrimination,  then we might also observe the value of 1.0 is an important benchmark.  If the Black to White ratio for the whole population (of median renters) were 1.0 then Blacks and Whites who pay the same rent generally get the same number of rooms.\n", "\n", "\n", "And if 1.0 is an acceptable benchmark, then we can proceed to estimate how (un)confident we are that there was discrimination in the rental market by...yes you guessed it... simulating some data  and comparing the observed BWRR to 1.0.\n", "\n", "If you didn't guess that, it's probably because you haven't seen it yet in data 8 -- but you will very shortly.\n", "\n", "In terms of data 8 we can speak of \"model\" wherein renters of median priced housing are equally likely to have the same amenities regardless of race.  According to that model the BWRR <i>statistic</i> should be 1.0.  The degree to which the BWRR falls short of 1 is a measure of discrimination in the housing market.\n", "\n", "But reminding ourselves that we are dealing with a *sample*, rather than a complete enumeration, the possibility emerges that even if the the true underlying world were without discrimination, we might still have an unlucky day in which an unusually high number of black headed households *with fewer than the typical number of rooms* just happened to be selected.\n", "\n", "That's the uncertainty that we want to quantify:\n", "\n", "What is the probability -- assuming that the true state of nature (your state's 1960 rental market) is without discrimination -- that we *could* draw a sample that nonetheless produces a BWTR of less than 1?\n", "\n", "## Let's ponder this\n", "\n", "1. Does the size of the sample make a difference?\n", "1. Does the size of the underlying population make a difference?\n", "\n", "## Simulating a discrimination free world\n", "\n", "The most straight forward data 8 sort of way to look at this problems is with a model as is done in Chapter 11.1 of the text book --  Look for *Swain v Alabama*.  As in the example from the book, our model of the universe is one in which there is no discrimination. In the context of toilets that means that anyone who pays the same amount of rent should be equally likely to have a toilet in other words, in our model universe, the BWTR should be 1 with variation due only to the randomness of our sample.\n", "\n", "\n"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["## select some"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["## simulating a color blind market\n", "rent50=st60.where('PERNUM',1).where('rentDecile',70)\n", "result=[]\n", "for trial in np.arange(100):\n", "    smp=rent50.sample(with_replacement=False).select(['rooms'])\n", "    smp.append_column('race',rent50['race'])\n", "    res=smp.group(\"race\",np.mean)\n", "    result.append(res['rooms mean'][0]/res['rooms mean'][1])\n", "np.mean(result)"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["# draw histogram of simulated result (BW ratio under color blind model)\n", "plt.hist(result)\n", "# compute the BWratio observed in the data\n", "tratio=rent50.select(['race','rooms']).group('race',np.mean)\n", "print(tratio)\n", "BWratio=tratio['rooms mean'][0]/tratio['rooms mean'][1]\n", "BWratio\n", "# add the red dot of observed reality to the histogram\n", "plt.scatter(BWratio, 0, color='red', s=30)\n", "plt.title(\"Histogram of uncertainty with red dot of reality\")\n", "print(\"simulated values less than observed: {}\".format(np.sum(result <= BWratio)))"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## So what's the bottom line:\n", "\n", "It depends on your state of course, but in general, you're probably looking at a pretty normal bell shaped sort of histogram with a red dot over to the left entirely beyond the left most bar of the histogram.  \n", "\n", "###Fill in the blank:\n", "\n", "The probability of observing a BWratio as low(high) as the observed BWratio is approximately _*BLANK*_."], "cell_type": "markdown"}, {"metadata": {}, "source": ["## Your turn\n", "\n", "Your task now is to repeat the above analysis for two additional variables: \n", "\n", "1. HotWater -- the presence of piped hotwater in the house\n", "1. Toilet -- the exclusive use of an indoor toilet in the house\n", "\n", "### NOTE:\n", "\n", "1. Since these two variables are True/False rather than numerical (like the number of rooms) the mean of these variables is equivalent to the proportion of the population for which the value of the variable is \"True\".  This presents no problem you can still take the Black:White ratio as we did above and make all the same computations.\n", "1. The two new variables are computed for you in the next cell. Note the CaptAliZation.\n"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": null, "source": ["st60.append_column('HotWater',[x =='Hot and cold piped water' for x in st60['hotwater']])\n", "st60.append_column('Toilet',[x =='Yes, exclusive use' for x in st60['toilet']])\n", "print()"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["cquiz('greatmig01-signif')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["cquiz('greatmig01-disc')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["cquiz('greatmig01-hot')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["cquiz('greatmig01-toilet')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["cquiz('greatmig01-tbd0')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "execution_count": null, "source": ["cquiz('greatmig01-tbd1')"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## That's it for part 1 of the great migration lab\n", "\n", "Please take a minute to evaluate your experience on this lab.  And remember to look on the course calendar for readings for next week."], "cell_type": "markdown"}, {"metadata": {"scrolled": true}, "execution_count": 92, "source": ["cquiz('greatmig01-eval')"], "cell_type": "code", "outputs": [{"metadata": {}, "output_type": "display_data", "data": {"text/html": ["\n", "        <iframe\n", "            width=\"1000\"\n", "            height=\"400\"\n", "            src=\"https://courses.demog.berkeley.edu/mason88/cgi-bin/quiz.py?qno=greatmig01-eval&sid=1353100\"\n", "            frameborder=\"0\"\n", "            allowfullscreen\n", "        ></iframe>\n", "        "], "text/plain": ["<IPython.lib.display.IFrame at 0x1a1e91b400>"]}}]}, {"metadata": {}, "execution_count": null, "source": [], "cell_type": "code", "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "version": "3.7.0", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat_minor": 2, "nbformat": 4}