{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Demography 88<br>\n", "Fall 2018<br>\n", "Carl Mason (cmason@berkeley.edu)<br>\n", "\n", "# Lab 7  The wage impacts of immigration \n", "\n", "## Outline\n", "1. Review TVD results from Great Migration (chicago) Lab\n", "1. Discuss The Clemens paper\n", "1. Consider what a productivity measuring statistic might look like\n", "    1. Design a productivity based statistic of interest\n", "    1. Compute the statistic\n", "    1. Characterize its uncertainty with a bootstrap simulation\n", "\n", "\n", "## The Clemens paper\n", "\n", "1. Huge gains from removing restrictions on immigration\n", "   1. Reasons why the trillion dollar bill is left on the sidewalk:\n", "1. Assumptions and requirements\n", "   1. migrants from poor to rich countries see large productivity gains\n", "       1. productivity = output/unit of input in this case labor. marginal productivity = wage\n", "       1. productivity is a matter of place ?  or person (migration selectivity)?\n", "   1. gain/loss to others hard to estimate BUT presumed minor/caneling/merely pecuniary\n", "       1. wages might rise in poor countries\n", "       1. wages might fall in rich countries\n", "       1. returns to other factors (capital) might rise in rich countries\n", "       1. returns to other factors (capital) might fall in poor countries\n", "       1. Not all externalities deserve a \"pigovian tax\"\n", "           1. smoke stacks yes; price/wage changes *no*\n", "   1. lots of models with production functions; general equilibrium & etc \n", "\n", "### A smaller but livlier version of Clemens' figure 1\n", "\n", "<a href=\"http://shiny.demog.berkeley.edu/carlm/EconImmig0/\" target=\"_new\"> Neoclassical model of wage effects of immigration</a>\n", "\n", "\n", "\n", "<img src=\"https://courses.demog.berkeley.edu/mason88/images/clemensFig1.png\">\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell to import the stuff we'll need\n", "import pandas as pd\n", "import numpy as np\n", "import scipy as sp\n", "import matplotlib.pyplot as plt \n", "plt.style.use('fivethirtyeight')\n", "\n", "%matplotlib inline\n", "from datascience import Table\n", "from datascience.predicates import are\n", "from datascience.util import *\n", "\n", "from IPython.display import HTML, IFrame, display\n", "datasite=\"https://courses.demog.berkeley.edu/mason88/data/\"\n", "quizsite=\"https://courses.demog.berkeley.edu/mason88/cgi-bin/quiz.py\"\n", "  \n", "def cquiz(qno) : \n", "    import IPython, requests \n", "    try:\n", "        sid\n", "    except NameError: \n", "        print(\"HEY! did you enter your sid way up at the top of this notebook?\")\n", "    Linkit='{0}?qno={1}&sid={2}'.format(quizsite,qno,sid)\n", "    #print(Linkit)\n", "    html = requests.get(Linkit)\n", "    #display(IFrame(Linkit, 1000, 300))\n", "    display(IFrame(Linkit, 1000, 400))\n", "\n", "\n", "    \n", "######################\n", "# Here it is ... the obvious place to put your student id\n", "sid=\"\"\n", "######################\n", "if sid == \"\" :\n", "    print(\"HEY! didn't I tell you to put your sid in the obvious place\")\n", " \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### #### #### ####\n", "###  SELECTING  LAB  PARTNERS\n", "### ### #### ####\n", "\n", "N=18\n", "numbers=np.arange(N)\n", "print(np.mod(N,2))\n", "if (not np.mod(N,2) == 0) :\n", "    numbers=np.append(numbers,\"lucky\")\n", "    N+=1\n", "numbersTab=Table().with_column('n',numbers)\n", "randomized=numbersTab.sample(k=N,with_replacement=False)\n", "selection=randomized['n']\n", "selection.shape = (2,int(N/2))\n", "Table().with_columns('zero',selection[0],'one',selection[1]).show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cquiz('wageimp0-partners')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The data for this week\n", "\n", "1. Residents of California, New York, Illinois, or Texas In 2000 and 2015\n", "1. Ages grouped by age and time 25-30 yrs old (in 2000) vs 40-45 (in 2015)\n", "1. Immigrants who arrived at ages 20-25\n", "1. productivity = Total Annual Wages/(usual hr per week * weeks worked last year) \n", "1. educ4 = education level coded into 5 mutually exclusive groups\n", "1. Data come from American Community Survey via IPUMS\n", "1. Data include weights which we must use.\n", ">Steven Ruggles, Katie Genadek, Ronald Goeken, Josiah Grover, and Matthew Sobek. Integrated Public Use Microdata Series: Version 6.0 [dataset]. Minneapolis: University of Minnesota, 2015. http://doi.org/10.18128/D010.V6.0.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Read the data and examine the columns\n", "wg=Table().read_table(datasite+'earnings2015new.csv')\n", "## adding a column \"age\" to avoid clumsy typing\n", "wg.append_column('age',['old' if a > 35 else 'young' for a in wg['AGE']])\n", "wg.where('immig',False).where('YEAR',2000).show(10)\n", "wg.where('immig',True).where('YEAR',2000).show(10)\n", "wg.where('immig',False).where('YEAR',2015).show(10)\n", "wg.where('immig',True).where('YEAR',2015).show(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Before we proceed with science, let's discuss the strengths and weaknesses of the data.\n", "\n", "1. Did the world change between 2000 and 2015 ?\n", "1. Are we observing the same people in 2000 and 2015 ?\n", "1. Are five year age categories ideal ?\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Productivity measure\n", "\n", "Clemens refers to productivity without defining it.  Which is reasonable because economists all know what it means: productivty = output/unit of input. Since the input is labor, Clemens is talking about *output per unit of labor* To confuse matters further, in figure 1,  includes **not** productivity but rather two *demand curves for labor* (one for rich countries the other for poor countries).\n", "\n", "productivity and demand for labor are linked by the \"fact\" that in a perfect market, the *marginal productivity of labor = the wage*. Thus wages are the key to everything. AND wages are  *theoretically* the productivity of the last worker hired aka the \"margingal productivity of labor\". \n", "\n", "We should perhaps discuss this in class.\n", "\n", "Having convinced ourselves of the above economics \"fact\" we can compute a measure of *marginal productivity* of various sources of labor--which is *sort of* what Clemens is talking about."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# computing productivity\n", "wg.append_column('prod',wg[\"INCWAGE\"]/(wg[\"UHRSWORK\"]*wg[\"wkswork\"]))\n", "\n", "tab0=wg.select(\"immig\",\"age\",\"prod\").groups(['age','immig'],np.nanmean)\n", "tab0.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cquiz(\"wage0-01\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Digression on PERWT \n", "\n", "The above table of means of marginal productivity by age and immigrant status is nice BUT as respectable data scientists, we must take note of the following:\n", "\n", "* These data comprise a structured random sample rather than a \"simple\" random sample, and thus it is <b> essential that we take account of weights</b> if we ever want to publish our results.\n", "    \n", "*  In the Great Migration labs, recall that when working with sums, it was proper to divide by .05 since the sample was a 5% simple random sample. Another way of thinking about that is that each observation in that Great Migration lab sample represented 20 people in the US in 1960.  Consequently, giving each observation a \"weight\" of 20 was appropriate in all computations.  Because *all* observations had a weight of 20, it was not necessary to explicitly include the weights when computing means -- because all those 20s would just cancel out.  NOT SO THIS TIME.\n", "\n", "*  In *this* data set, sampling was done according to a complicated set of rules that ensured that the sample would have much broader coverage in terms of geography and ethnicity than would a simple random sample of the same size.  The price we pay for that is that we must take weights into account *even when computing means*. While in the Great Migration sample, all weights were \"20\"  in this sample, the weights are stored in 'PERWT' and the variation across individuals is considerable."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Since the data from 2000 are drawn from a 5% sample, most observations have weights around 20 however, \n", "# the data from 2015 are a 1% sample so many observations should have weights of around 100 ... and of course,\n", "# there are a few that are way out there.\n", "\n", "print(wg.select(\"PERWT\").stats())\n", "wg.select('PERWT').hist(bins=100)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### So we can improve the table from the cell \"Computing productivity\" by using  *weighted means* rather than unweighted means.\n", "\n", "Weighted means are not hard to compute, but it involves an extra step. The formula is:\n", "\n", "$$ \\text{Weighted mean} = \\frac{\\sum_{i=1}^{N}{x_iw_i}}{\\sum_{i=1}^{N}{w_i}}$$\n", "\n", "where $x_i$ is the $i^{th}$ observation of the variable that you are taking the weighted mean of, and $w_i$ is the weight corresponding to the $i^{th}$ observation. In our present case, $x$ is a measure of productivity and $w$ is 'PERWT'.\n", "\n", "Actually, owing to the limitations of the Tables.group method, computing the weighted means also require some extra python -- which slows things down a bit."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# computing weighted productivity\n", "res=[]\n", "for a in np.unique(wg['age']):\n", "    for i in np.unique(wg['immig']) :\n", "        # create a table that is a subset of wg\n", "        temp=wg.where(\"immig\",i).where(\"age\",a)\n", "        # compute wtd mean the \"hard way\"\n", "        hard= np.sum(temp['prod']*temp['PERWT'])/np.sum(temp['PERWT'])\n", "        # and the \"easy way\"\n", "        easy=np.average(temp['prod'],weights=temp['PERWT'])\n", "        print(\"immig={0} age={1} wtd mean: hard={2} easy={3}\".format(i,a,hard,easy))\n", "        res.append({\"immig\":i,\"age\":a, \"wtdProd\":easy})\n", "Table.from_records(res)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cquiz('wage0-02')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## What conclusions might we draw from weighted means of marginal productivities?\n", "\n", "##### Do immigrants really lose ground as they gain experience in the US ?\n", "##### What other explanations might there be?\n", "\n", "#### Consider this statistic :\n", "\n", "$$ \\frac{\\text{prod}_{\\text{immig,old}}}{\\text{prod}_{\\text{immig,young}}}/  \\frac{\\text{prod}_{\\text{USborn,old}}}{\\text{prod}_{\\text{USborn,young}}} $$\n", "\n", "Can we justify the above statistic as an estimate of the degree to which immigrants lose(gain) ground (in relation to USborn wages) with experience in US labor markets?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Ratio of ratios \n", "res=dict()\n", "for a in np.unique(wg['age']):\n", "    for i in np.unique(wg['immig']) :\n", "        # create a table that is a subset of wg\n", "        temp=wg.where(\"immig\",i).where(\"age\",a)\n", "\n", "        easy=np.average(temp['prod'],weights=temp['PERWT'])\n", "        # store result in dictionary indexed by tuple\n", "        res[(i,a)]=easy\n", "# compute diff in ratio statistic        \n", "(res[True,'old']/res[True,'young']) / (res[False,'old']/res[False,'young'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cquiz('wage0-03')"]}, {"cell_type": "markdown", "metadata": {}, "source": [" ## And what about uncertainty ?\n", " \n", " Do I hear you crying out for a bootstrap?  or what ?\n", " \n", " 1. Write a function that computes the ratio-of-ratios statistic from a sample of wg records\n", " 1. Write a loop that draws a sample; calls the function to compute statistic; stores result\n", " 1. Interpret result"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Write Function that computes statistic\n", "def getStat(wg=wg) :\n", "    res=dict()\n", "    for a in np.unique(wg['age']):\n", "        for i in np.unique(wg['immig']) :\n", "            # create a table that is a subset of wg\n", "            \n", "            temp=wg.where(\"immig\",i).where(\"age\",a)\n", "\n", "            easy=np.average(temp['prod'],weights=temp['PERWT'])\n", "            # store result in dictionary indexed by tuple so we can use it later\n", "            res[(i,a)]=easy\n", "    # compute diff in ratio statistic        \n", "    return((res[True,'old']/res[True,'young'])/( res[False,'old']/res[False,'young']))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "##### Write loop that..\n", "# draws samples; computes and stores the statistic for each sample\n", "##\n", "bs=[]\n", "for n in np.arange(10):\n", "    # note end='\\r'  this will address our impatience.\n", "    print('sampling iteration: {0}'.format(n),end='\\r')\n", "\n", "    \"bs.append(getStat(?????))\"\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["### Interpret the result\n", "\n", "Table().with_columns('bs',bs).hist()\n", "plt.scatter(np.percentile(bs,[5,95]), [0,0], color='red', s=30)\n", "plt.scatter(getStat(wg),0 ,color='blue',s=30)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "outputs": [], "source": ["cquiz('wage0-04')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Where do we go next?\n", "\n", "So based on the above analysis,  we are have a result that indicates that overall, immigrants tend to become less productive relative to US born workers as they gain experience in the US labor market.  Is it just me, or does that also strike you as odd?  Many immigrants arrive in the US unable to speak english and without much in the way of job networks or experience with US work place norms.  Could language skills and experience in the US really make immigrants *less* productive ?\n", "\n", "Really ?  Let's discuss this in class and agree that you should try our analysis on subsets of the data .. \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## On your own ...\n", "\n", "copy cells from above as needed and write some additional code to redo our analysis for immigrants from *individual* countries.  Specifically, for the four largest countries of origin, compute the ratio of ratios statistic **AND** run the bootstrap procedure to construct 90% confidence bounds.\n", "\n", "## Here is a code snippet that you might find valuable\n", "\n", "`wg.append_column('keep',[(w['bpl']==\"China\") | (w['immig'] == False )for w in wg.to_array()])`\n", "\n", "Hints:\n", " - You only need to copy and modify the cells called \"Write loop that ...\"  and \"Interpret the result\".\n", " - You can get away with running only 25 bootstrap samples ... but more is better.\n", " - The cell below can inform us as to which are the largest origin countries of US immigrants."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# which are the four\n", "wg.where('immig', True).group('bpl').sort('count',descending=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Here is a blank cell for your work"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cquiz('wage0-05')"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["cquiz('wage0-06')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## That is for Lab 7\n", "\n", "###  Please take the trouble to evaluate so that next year's students' sufferring can be reduced."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cquiz('wage0-eval')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.5"}}, "nbformat": 4, "nbformat_minor": 2}